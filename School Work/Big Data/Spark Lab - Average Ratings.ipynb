{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting AvgMovieRatings.py\n"
     ]
    }
   ],
   "source": [
    "%%file AvgMovieRatings.py\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "class SparkAverageRatings:\n",
    "    #returns movie names and movieid (movieID, movieName)\n",
    "    def load_movie_names():\n",
    "        movie_names = {}\n",
    "        with open('u.item') as file:\n",
    "            for line in file:\n",
    "                fields = line.split('|')\n",
    "                movie_names[int(fields[0])] = fields[1]\n",
    "        return movie_names\n",
    "    \n",
    "    #parse u.data file to get (movieID,(rating, 1))\n",
    "    def parse_input(line):\n",
    "        fields = line.split()\n",
    "        return (int(fields[1]),(float(fields[2]), 1)) #why not int?\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        #define context and configuration of program\n",
    "        obj_conf = SparkConf().setAppName('AverageMovieRating')\n",
    "        ctx = SparkContext(conf = obj_conf)\n",
    "        ctx.setLogLevel('ERROR')\n",
    "        \n",
    "        #Load movie names to use when displaying\n",
    "        movie_names = load_movie_names()\n",
    "        \n",
    "        #Load the ratings data file\n",
    "        lines = ctx.textFile('u.data')\n",
    "        \n",
    "        #Load the data file as an RDD using parse input method (movieID, (rating,1))\n",
    "        movie_rdd = lines.map(parse_input)\n",
    "        \n",
    "        #Reduce the ratings by key movieID => (sumratings, ratingsCt)\n",
    "        movie_counts = movie_rdd.reduceByKey(lambda mov_1, mov_2: (mov_1[0] + mov_2[0], mov_1[1] + mov_2[1]))\n",
    "\n",
    "        #Map output values to final calculation for each movieID => (movieID, average movie rating)\n",
    "        movie_avg = movie_counts.mapValues(lambda totals: round(totals[0]/totals[1], 2))\n",
    " \n",
    "        #print results to screen\n",
    "        results = movie_avg.take(30)\n",
    "        print()\n",
    "        print()\n",
    "        print('----------------------------------------------------------------')\n",
    "        print()\n",
    "        print()\n",
    "        for line in results:\n",
    "            print(movie_names[line[0]], line[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "Kolya (1996) 3.99\n",
      "L.A. Confidential (1997) 4.16\n",
      "Jackie Brown (1997) 3.64\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963) 4.25\n",
      "Remains of the Day, The (1993) 3.94\n",
      "Romy and Michele's High School Reunion (1997) 3.06\n",
      "Star Trek: First Contact (1996) 3.66\n",
      "To Wong Foo, Thanks for Everything! Julie Newmar (1995) 2.89\n",
      "Sabrina (1995) 3.5\n",
      "Just Cause (1995) 3.14\n",
      "Endless Summer 2, The (1994) 2.5\n",
      "Man Without a Face, The (1993) 3.54\n",
      "Sabrina (1954) 3.8\n",
      "Die Hard (1988) 3.87\n",
      "Twister (1996) 3.22\n",
      "Broken Arrow (1996) 3.03\n",
      "Casper (1995) 3.08\n",
      "Jaws (1975) 3.77\n",
      "Chasing Amy (1997) 3.94\n",
      "Silence of the Lambs, The (1991) 4.29\n",
      "Sleepless in Seattle (1993) 3.54\n",
      "Sting, The (1973) 4.06\n",
      "Speechless (1994) 3.08\n",
      "Crumb (1994) 3.79\n",
      "French Twist (Gazon maudit) (1995) 3.21\n",
      "Fly Away Home (1996) 3.54\n",
      "Tales from the Hood (1995) 2.04\n",
      "Get Shorty (1995) 3.55\n",
      "Kiss the Girls (1997) 3.46\n",
      "Fargo (1996) 4.16\n",
      "SUCCESS: The process with PID 3008 (child process of PID 5624) has been terminated.\n",
      "SUCCESS: The process with PID 5624 (child process of PID 2404) has been terminated.\n",
      "SUCCESS: The process with PID 2404 (child process of PID 12060) has been terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/03/31 17:16:16 ERROR Shell: Failed to locate the winutils binary in the hadoop binary path\n",
      "java.io.IOException: Could not locate executable null\\bin\\winutils.exe in the Hadoop binaries.\n",
      "\tat org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:379)\n",
      "\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:394)\n",
      "\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:387)\n",
      "\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)\n",
      "\tat org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:273)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:261)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:791)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:761)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:634)\n",
      "\tat org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2422)\n",
      "\tat org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2422)\n",
      "\tat scala.Option.getOrElse(Option.scala:121)\n",
      "\tat org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2422)\n",
      "\tat org.apache.spark.SecurityManager.<init>(SecurityManager.scala:79)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.secMgr$lzycompute$1(SparkSubmit.scala:348)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$secMgr$1(SparkSubmit.scala:348)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7.apply(SparkSubmit.scala:356)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7.apply(SparkSubmit.scala:356)\n",
      "\tat scala.Option.map(Option.scala:146)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:355)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:774)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n",
      "20/03/31 17:16:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "\n",
      "[Stage 0:>                                                          (0 + 2) / 2]\n",
      "[Stage 0:=============================>                             (1 + 1) / 2]\n",
      "[Stage 1:>                                                          (0 + 1) / 1]\n",
      "                                                                                \n"
     ]
    }
   ],
   "source": [
    "!python AvgMovieRatings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
